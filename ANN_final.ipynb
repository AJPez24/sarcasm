{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcastic comments: 0\n",
      "Non-sarcastic comments: 12704751\n",
      "Top 10 authors: [('[deleted]', 297775), ('mirandaBBfan', 2226), ('timewaitsforsome', 1747), ('bulnreinhart', 1735), ('Gundam336', 1727), ('Tiffosi', 1274), ('HeyDontSlip', 1262), ('Based06', 1243), ('GoSomaliPirates', 1155), ('dbauer0706', 1127)]\n",
      "Top 10 subreddits: [('AskReddit', 2448608), ('pics', 659980), ('worldnews', 572368), ('politics', 526758), ('videos', 383311), ('funny', 374652), ('news', 365579), ('todayilearned', 316996), ('gaming', 306898), ('pcmasterrace', 306737)]\n"
     ]
    }
   ],
   "source": [
    "# DATA EXPLORATION\n",
    "import pandas as pd \n",
    "\n",
    "# use ijson parser for large json file\n",
    "import ijson \n",
    "from collections import Counter\n",
    "\n",
    " # file with just text/author/subreddit/etc (no /s markers)\n",
    "comments = \"comments.json\"\n",
    "\n",
    "# counting sarcastic & not (data not available in this file)\n",
    "sarcastic_count = 0\n",
    "non_sarcastic_count = 0\n",
    "\n",
    "# coutning top authors & subreddits\n",
    "authors = []\n",
    "subreddits = []\n",
    "\n",
    "# json file is structured as a dictionary - go through key value pairs\n",
    "with open(comments, \"rb\") as f:\n",
    "    for key, value in ijson.kvitems(f, \"\"):\n",
    "        # check if comment has sarcasm indicator\n",
    "        text = value.get(\"text\", \"\")\n",
    "        if \"/s\" in text:\n",
    "            sarcastic_count += 1\n",
    "        else:\n",
    "            non_sarcastic_count += 1\n",
    "\n",
    "        authors.append(value.get(\"author\"))\n",
    "        subreddits.append(value.get(\"subreddit\"))\n",
    "\n",
    "print(\"Sarcastic comments:\", sarcastic_count) # 0\n",
    "print(\"Non-sarcastic comments:\", non_sarcastic_count) # 12,704,751\n",
    "\n",
    "# authors\n",
    "author_counts = Counter(authors).most_common(10)\n",
    "print(\"Top 10 authors:\", author_counts)\n",
    "\n",
    "# subreddits\n",
    "subreddit_counts = Counter(subreddits).most_common(10)\n",
    "print(\"Top 10 subreddits:\", subreddit_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcastic comments: 0\n",
      "Non-sarcastic comments: 128540\n"
     ]
    }
   ],
   "source": [
    "test = \"test-balanced.csv\"\n",
    "train = \"train-balanced.csv\"\n",
    "import csv\n",
    "\n",
    "sarcastic_count = 0\n",
    "non_sarcastic_count = 0\n",
    "authors = []\n",
    "subreddits = []\n",
    "\n",
    "with open(\"train-balanced.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        text = row.get(\"text\", \"\")\n",
    "        if \"/s\" in text:\n",
    "            sarcastic_count += 1\n",
    "        else:\n",
    "            non_sarcastic_count += 1\n",
    "\n",
    "        authors.append(row.get(\"author\"))\n",
    "        subreddits.append(row.get(\"subreddit\"))\n",
    "\n",
    "print(\"Sarcastic comments:\", sarcastic_count)\n",
    "print(\"Non-sarcastic comments:\", non_sarcastic_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                     id    code1    code2  label1  label2\n",
      "0                7uaac  c07fd66  c07fjge       1       0\n",
      "1                7u896  c07f3md  c07f3ls       1       0\n",
      "2                7visa  c07jcz3  c07it38       0       1\n",
      "3                7vq9q  c07jfvv  c07jy05       1       0\n",
      "4                7xdys  c07o37s  c07o350       1       0\n",
      "...                ...      ...      ...     ...     ...\n",
      "128536  62oyi7 dfo7koy  dfoaxnm  dfocp4d       1       0\n",
      "128537          62oypx  dfoplb5  dfo8536       0       1\n",
      "128538  62p1zh dfoiibk  dfoks1e  dfojn53       1       0\n",
      "128539          62p22t  dfp3fdl  dfog1nz       1       0\n",
      "128540          62p5z8  dfor4e3  dfohaos       1       0\n",
      "\n",
      "[128541 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "#parse train file \n",
    "import json\n",
    "train_rows = []\n",
    "\n",
    "with open(\"train-balanced.csv\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Split into 3 parts using '|'\n",
    "        part_id, part_codes, part_labels = line.split(\"|\")\n",
    "\n",
    "        # Split codes and labels by space\n",
    "        codes = part_codes.split()\n",
    "        labels = part_labels.split()\n",
    "\n",
    "        train_rows.append({\n",
    "            \"id\": part_id,\n",
    "            \"code1\": codes[0],\n",
    "            \"code2\": codes[1],\n",
    "            \"label1\": int(labels[0]),\n",
    "            \"label2\": int(labels[1])\n",
    "        })\n",
    "\n",
    "train_df = pd.DataFrame(train_rows)\n",
    "print(train_df.head)\n",
    "\n",
    "comments = []\n",
    "with open(\"comments.json\", \"r\") as f:\n",
    "    for line in f:\n",
    "        comments.append(json.loads(line))\n",
    "\n",
    "comments_df = pd.DataFrame(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     author  score  ups  \\\n",
      "0  Upvote For Simultaneous \"Million Person\" March...  [deleted]     48  104   \n",
      "1                      Economics (29654 subscribers)       pfft     14   14   \n",
      "2  Children in the Czech Republic are happier and...  [deleted]     29   48   \n",
      "3  Of course it's a \"less of a country\", those pe...  joe24pack      1    1   \n",
      "4  Here we go again: Israeli PM vows 'sharp respo...  [deleted]     14   23   \n",
      "\n",
      "   downs     date  created_utc  subreddit       id  \n",
      "0     56  2009-02   1233540251  Economics    7u4r6  \n",
      "1      0  2009-02   1233549003  Economics  c07ewjj  \n",
      "2     19  2009-02   1233533923  worldnews    7u4a5  \n",
      "3      0  2009-02   1233553378  worldnews  c07ey0j  \n",
      "4      9  2009-02   1233502066  worldnews    7u1ht  \n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "for comment_id in comments_df.columns:\n",
    "    entry = comments_df.iloc[0][comment_id]   # extract the dict\n",
    "    entry[\"id\"] = comment_id                  # add the ID into the dict\n",
    "    records.append(entry)\n",
    "\n",
    "comments_normalized = pd.DataFrame(records)\n",
    "print(comments_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_normalized.to_csv(\"data/clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
